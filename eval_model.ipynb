{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import BertTokenizer, AutoModelForSequenceClassification, PreTrainedTokenizerFast, LineByLineTextDataset, pipeline, BertConfig, AutoTokenizer, BertModel,BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import AutoConfig\n",
    "import os\n",
    "import json\n",
    "\n",
    "from script.tokenizer import KmerTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, device(type='cuda'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.current_device(), device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\Auguste Verdier\\Desktop\\ADNe\\BouillaClip\\Data\\TeleoSplit\\train_aug_nodupl_300.csv\")\n",
    "val_df = pd.read_csv(r\"C:\\Users\\Auguste Verdier\\Desktop\\ADNe\\BouillaClip\\Data\\TeleoSplit\\val_genera.csv\")\n",
    "test_df  = pd.read_csv(r\"C:\\Users\\Auguste Verdier\\Desktop\\ADNe\\BouillaClip\\Data\\TeleoSplit\\test_genera.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCCAAACAATAAACACACGAAACTAACTAAAATGCTTCGAACCGT...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Scombriformes</td>\n",
       "      <td>Gempylidae</td>\n",
       "      <td>Promethichthys</td>\n",
       "      <td>Promethichthysprometheus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCCCAAGTTCAATATATCCTTCTAACTAAGAAGTTAGCCGAACAAA...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Salmoniformes</td>\n",
       "      <td>Salmonidae</td>\n",
       "      <td>Oncorhynchus</td>\n",
       "      <td>Oncorhynchusmasou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCGAACTTAACCCACGAACCTTACCTAAACTGTTTTACATGAAA...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Holocentriformes</td>\n",
       "      <td>Holocentridae</td>\n",
       "      <td>Neoniphon</td>\n",
       "      <td>Neoniphonargenteus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCCCTGTTAAACAGCAACCAATGTAAATAACACAAAAGCACCAACG...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Cypriniformes</td>\n",
       "      <td>Gastromyzontidae</td>\n",
       "      <td>Yaoshania</td>\n",
       "      <td>Yaoshaniapachychilus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCAAGCTTCCGGCCCTAATTAATTAAAACCCTACAACTGCAAAG...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Istiophoriformes</td>\n",
       "      <td>Istiophoridae</td>\n",
       "      <td>Istiophorus</td>\n",
       "      <td>Istiophorusplatypterus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91010</th>\n",
       "      <td>CCCCAAACCATTAGAATAAGTAATTAGACCTCCATACGACAAAGGG...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Lophiiformes</td>\n",
       "      <td>Diceratiidae</td>\n",
       "      <td>Synthetic</td>\n",
       "      <td>Diceratiaspileatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91011</th>\n",
       "      <td>CACCAAACCAATAGAATGAGTATTTTAACGCCGTTAGGACAAAGGG...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Lophiiformes</td>\n",
       "      <td>Diceratiidae</td>\n",
       "      <td>Synthetic</td>\n",
       "      <td>Diceratiaspileatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91012</th>\n",
       "      <td>CCCCAAATCATTAGACTTGGGAATTAAATCATCAGAATACAAAGGG...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Lophiiformes</td>\n",
       "      <td>Diceratiidae</td>\n",
       "      <td>Synthetic</td>\n",
       "      <td>Diceratiaspileatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91013</th>\n",
       "      <td>CCCCACACCAATAAACTACGTCATTAAACCACCAGGAAACAAAGGG...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Lophiiformes</td>\n",
       "      <td>Diceratiidae</td>\n",
       "      <td>Synthetic</td>\n",
       "      <td>Diceratiaspileatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91014</th>\n",
       "      <td>CCCCAAACCAATAGACTACGTAATTAATCCGTGTTAAATCAAAGGG...</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>Lophiiformes</td>\n",
       "      <td>Diceratiidae</td>\n",
       "      <td>Synthetic</td>\n",
       "      <td>Diceratiaspileatus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91015 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sequence    phylum  \\\n",
       "0      CCCCAAACAATAAACACACGAAACTAACTAAAATGCTTCGAACCGT...  Chordata   \n",
       "1      CCCCAAGTTCAATATATCCTTCTAACTAAGAAGTTAGCCGAACAAA...  Chordata   \n",
       "2      CCCCGAACTTAACCCACGAACCTTACCTAAACTGTTTTACATGAAA...  Chordata   \n",
       "3      CCCCTGTTAAACAGCAACCAATGTAAATAACACAAAAGCACCAACG...  Chordata   \n",
       "4      CCCCAAGCTTCCGGCCCTAATTAATTAAAACCCTACAACTGCAAAG...  Chordata   \n",
       "...                                                  ...       ...   \n",
       "91010  CCCCAAACCATTAGAATAAGTAATTAGACCTCCATACGACAAAGGG...  Chordata   \n",
       "91011  CACCAAACCAATAGAATGAGTATTTTAACGCCGTTAGGACAAAGGG...  Chordata   \n",
       "91012  CCCCAAATCATTAGACTTGGGAATTAAATCATCAGAATACAAAGGG...  Chordata   \n",
       "91013  CCCCACACCAATAAACTACGTCATTAAACCACCAGGAAACAAAGGG...  Chordata   \n",
       "91014  CCCCAAACCAATAGACTACGTAATTAATCCGTGTTAAATCAAAGGG...  Chordata   \n",
       "\n",
       "             class             order            family           genus  \\\n",
       "0      Actinopteri     Scombriformes        Gempylidae  Promethichthys   \n",
       "1      Actinopteri     Salmoniformes        Salmonidae    Oncorhynchus   \n",
       "2      Actinopteri  Holocentriformes     Holocentridae       Neoniphon   \n",
       "3      Actinopteri     Cypriniformes  Gastromyzontidae       Yaoshania   \n",
       "4      Actinopteri  Istiophoriformes     Istiophoridae     Istiophorus   \n",
       "...            ...               ...               ...             ...   \n",
       "91010  Actinopteri      Lophiiformes      Diceratiidae       Synthetic   \n",
       "91011  Actinopteri      Lophiiformes      Diceratiidae       Synthetic   \n",
       "91012  Actinopteri      Lophiiformes      Diceratiidae       Synthetic   \n",
       "91013  Actinopteri      Lophiiformes      Diceratiidae       Synthetic   \n",
       "91014  Actinopteri      Lophiiformes      Diceratiidae       Synthetic   \n",
       "\n",
       "                        species  \n",
       "0      Promethichthysprometheus  \n",
       "1             Oncorhynchusmasou  \n",
       "2            Neoniphonargenteus  \n",
       "3          Yaoshaniapachychilus  \n",
       "4        Istiophorusplatypterus  \n",
       "...                         ...  \n",
       "91010        Diceratiaspileatus  \n",
       "91011        Diceratiaspileatus  \n",
       "91012        Diceratiaspileatus  \n",
       "91013        Diceratiaspileatus  \n",
       "91014        Diceratiaspileatus  \n",
       "\n",
       "[91015 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_save=r\"C:\\Users\\Auguste Verdier\\Desktop\\ADNe\\BouillaClip\\Model\\genera_300_medium_3_mer\\checkpoint-85335\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder on the combined data\n",
    "label_encoder.fit(pd.concat([train_df['family'], val_df['family']]))\n",
    "\n",
    "# Encode the labels\n",
    "train_labels = label_encoder.transform(train_df['family'])\n",
    "val_labels = label_encoder.transform(val_df['family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "label2id = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "## TOKENIZER\n",
    "tokenizer=KmerTokenizer(3, trust_remote_code=True,add_special_tokens=False)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path_save, trust_remote_code=True)\n",
    "\n",
    "if not tokenizer.pad_token:\n",
    "    print(\"add one\")\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCC', 'CCC', 'CCC', 'CCC', 'CCG', 'CGT', 'GTG', 'TGA', 'GAG', 'AGT', 'GTA', 'TAA', 'AAT', 'ATG', 'TGC', 'GCC', 'CCC', 'CCT', 'CTG', 'TGA', 'GAC', 'ACA', 'CAG', 'AGT', 'GTT', 'TTT', 'TTT', 'TTA', 'TAT', 'ATA', 'TAT', 'ATC', 'TCC', 'CCT', 'CTA', 'TAA', 'AAA', 'AAA', 'AAC', 'ACG', 'CGA', 'GAG', 'AGG', 'GGA']\n"
     ]
    }
   ],
   "source": [
    "seq=\"GCCCCCGTGAGTAATGCCCTGACAGTTTTATATCCTAAAACGAGGA\"\n",
    "print(tokenizer.tokenize(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Auguste Verdier\\.cache\\huggingface\\modules\\transformers_modules\\zhihan1996\\DNABERT-2-117M\\d064dece8a8b41d9fb8729fbe3435278786931f1\\bert_layers.py:129: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(os.path.join(model_path_save,\"config.json\"), \n",
    "                                    num_labels=len(id2label), \n",
    "                                    max_position_embeddings=510,\n",
    "                                    id2label=id2label,\n",
    "                                    label2id=label2id\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path_save, trust_remote_code=True, ignore_mismatched_sizes=True, config=config).to(device)\n",
    "\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_df['sequence'].tolist(), truncation=True, max_length=510)\n",
    "val_encodings = tokenizer(val_df['sequence'].tolist(), truncation=True, max_length=510)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': train_labels\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask'],\n",
    "    'labels': val_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 768]) torch.Size([1, 64, 768])\n",
      "tensor([[[ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         ...,\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.0423, -0.0375,  0.0128,  ..., -0.0286, -0.0231, -0.0274],\n",
      "         [-0.0106, -0.0621, -0.0159,  ...,  0.0545,  0.0286, -0.0168],\n",
      "         [-0.0106, -0.0621, -0.0159,  ...,  0.0545,  0.0286, -0.0168],\n",
      "         ...,\n",
      "         [ 0.0496,  0.0425, -0.0914,  ...,  0.0228, -0.0616, -0.0226],\n",
      "         [-0.0428, -0.0500, -0.0098,  ..., -0.0225,  0.0258,  0.0499],\n",
      "         [-0.0269, -0.0381, -0.0309,  ..., -0.0306, -0.0243, -0.0291]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Leuciscidae': 0.7230259776115417}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"CCCCTGTCAAAATGCAATAAAGATATTTAATACCAAAGCGCTGACAAGGGGAGGCAAGTCGTAA\" # Leuciscidae\n",
    "classifier = pipeline(\"sentiment-analysis\", model=trainer.model, tokenizer=tokenizer,device=0)\n",
    "results = classifier(text)\n",
    "\n",
    "labels = [result['label'] for result in results]\n",
    "scores = [result['score'] for result in results]\n",
    "\n",
    "label_scores = dict(zip(labels, scores))\n",
    "label_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/92463 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCCCCCGTGAGTAATGCCCTGACAGTTTTATATCCTAAAACGAGGAGCTGGCATCAGGCACAACCCCCCGTTAGCCCACGACGCCTCGCTTAGCCACACCCCCAAGGGAATTTCAGCAGTGATAAACCTTAAGCCATAAGTGAAAACTAGACTTAGTAACAGCTAATAAGGGCTGGTAAAACTCGTGCCAGCCGCCGCGGTTATACGAGTGGCCCAAGTTGATAAAAACCGGCGTAAAGCGTGGTTAAGGTCATACTACAAACTAAAGCCGAACCTCCTCACAGCAGTTATACGCTTATGAAGAAACTGAAGCTCCCCCACGAAAGTGGCTTTACTACCCCACCTGACCCCACGAAAGCTATGGCCCAAACTGGGATTAGAGACCCCACTATGCATAGCTGTAAACCCTGACAGATTTTTACATCCCCTGTCCGCCCGGGTACTACGCGCGTCAGCGTAAAACCCAAAGGACTTGGCGGTTCTTTAGACCCCCTAGAGGAGCCTGTTCTATAACCGATAATCCCCGTTAAACCTCACCCTCTCTTGCCTATCCCGCCTATATACCGCCGTCGTCAGCTACCCCTGTGAAGGATGAACAGCTAGCAAGATTGGTACCACCCAAAACGTCAGGTCCAGGTGTAGCGTATGAGAGGGGCAGAAATGGGCTACATTCGCTAATTTAGCGAACACGAACGATGTACTGAAAAAATACATCCGAAGGAGGATTTAGCAGTAAGTAGGAAGCAGAGCGTCCCACTGAAGCCGGCTCTGAAGTGCGTACACACCGCCCGTCACTTTCCCCAAACAATAAACACACGAAACTAACTAAAATGCTTCGAACCGTTAAGGGGAAACAAGTCGTAACATGGTAAGTGTACCGGAAGGTGTACTTGGCAATATCC\n",
      "torch.Size([1, 904, 768]) torch.Size([1, 902, 768])\n",
      "tensor([[[ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         ...,\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020],\n",
      "         [ 0.0287,  0.0005,  0.1000,  ...,  0.0044, -0.0054, -0.0020]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.0423, -0.0375,  0.0128,  ..., -0.0286, -0.0231, -0.0274],\n",
      "         [ 0.0984, -0.1267, -0.0191,  ..., -0.1052,  0.0549,  0.0168],\n",
      "         [-0.0106, -0.0621, -0.0159,  ...,  0.0545,  0.0286, -0.0168],\n",
      "         ...,\n",
      "         [-0.0664,  0.0866, -0.1041,  ..., -0.0760,  0.0284, -0.1484],\n",
      "         [ 0.0362, -0.1292, -0.0429,  ..., -0.0053, -0.1137, -0.0304],\n",
      "         [-0.0269, -0.0381, -0.0309,  ..., -0.0306, -0.0243, -0.0291]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (904) must match the size of tensor b (902) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels, predictions, dict_score\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Call the function with the file path\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m labels, predictions, dict_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAuguste Verdier\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mADNe\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDATASET\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mLAST 12S\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mtrain.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 34\u001b[0m, in \u001b[0;36mcalculate_predictions\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#se=\"CCCCTGTCAAAATGCAATAAAGATATTTAATACCAAAGCGCTGACAAGGGGAGGCAAGTCGTAA\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msequence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# pred=classifier(se)[0]['label'] \u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#print(pred,lab,1*(lab==pred))\u001b[39;00m\n\u001b[0;32m     39\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[1;32m--> 156\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\transformers\\pipelines\\base.py:1254\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1247\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m         )\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\transformers\\pipelines\\base.py:1261\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1260\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1261\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1262\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\transformers\\pipelines\\base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1160\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1161\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\zhihan1996\\DNABERT-2-117M\\d064dece8a8b41d9fb8729fbe3435278786931f1\\bert_layers.py:862\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    842\u001b[0m     input_ids: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;66;03m# (mean-square loss). If `config.num_labels > 1` a classification loss\u001b[39;00m\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# is computed (cross-entropy).\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 862\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    876\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\zhihan1996\\DNABERT-2-117M\\d064dece8a8b41d9fb8729fbe3435278786931f1\\bert_layers.py:599\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, position_ids, output_all_encoded_layers, masked_tokens_mask, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    597\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(input_ids)\n\u001b[1;32m--> 599\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m subset_mask \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    603\u001b[0m first_col_mask \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\zhihan1996\\DNABERT-2-117M\\d064dece8a8b41d9fb8729fbe3435278786931f1\\bert_layers.py:102\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m( token_type_embeddings)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs_embeds)\n\u001b[1;32m--> 102\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken_type_embeddings\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# no position embeddings! ALiBi\u001b[39;00m\n\u001b[0;32m    104\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (904) must match the size of tensor b (902) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "def calculate_predictions(file_path):\n",
    "\n",
    "    \n",
    "    # Initialize lists to store the data\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    dict_score=dict()\n",
    "\n",
    "\n",
    "\n",
    "    testfile = pd.read_csv(file_path)\n",
    "\n",
    "    #sp=read_list('test_1_spe.json')\n",
    "    sp=testfile['species'].unique()\n",
    "    # for f in testfile['family'].unique():\n",
    "    #     dict_score[f]=(0,0)\n",
    "\n",
    "    \n",
    "\n",
    "    for index, row in tqdm(testfile.iterrows(),total=testfile.shape[0]):\n",
    "        #print(row['sequence'])\n",
    "        lab=row['family']\n",
    "        \n",
    "\n",
    "        if row['species'] in sp:\n",
    "        \n",
    "            \n",
    "            if lab not in dict_score :\n",
    "                dict_score[lab]=[0,0]\n",
    "            \n",
    "            print(row['sequence'])\n",
    "            #se=\"CCCCTGTCAAAATGCAATAAAGATATTTAATACCAAAGCGCTGACAAGGGGAGGCAAGTCGTAA\"\n",
    "            pred = classifier(row['sequence'])[0]['label']\n",
    "            # pred=classifier(se)[0]['label'] \n",
    "            #print(pred,lab,1*(lab==pred))\n",
    "\n",
    "\n",
    "            predictions.append(pred)\n",
    "\n",
    "            labels.append(row['family'])\n",
    "\n",
    "            succes,total=dict_score[lab]\n",
    "\n",
    "\n",
    "            dict_score[lab]=succes+1*(lab==pred),total+1\n",
    "        #print(pred,lab,pred==lab)\n",
    "\n",
    "\n",
    "    # Calculate accuracy\n",
    "    #accuracy = np.mean(np.array(predictions) == np.array(labels)) * 100\n",
    "\n",
    "    #labs = set(predictions + labels)\n",
    "    \n",
    "    # Create a confusion matrix\n",
    "    #cm = confusion_matrix(labels, predictions, labs)\n",
    "    \n",
    "    return labels, predictions, dict_score\n",
    "\n",
    "# Call the function with the file path\n",
    "labels, predictions, dict_score = calculate_predictions(r\"C:\\Users\\Auguste Verdier\\Desktop\\ADNe\\DATASET\\LAST 12S\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6323357947920714"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(predictions) == np.array(labels)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2573\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Carangidae': (7, 9),\n",
       " 'Cyprinidae': (38, 39),\n",
       " 'Salmonidae': (6, 6),\n",
       " 'Nemipteridae': (2, 2),\n",
       " 'Rajidae': (6, 6),\n",
       " 'Carcharhinidae': (10, 10),\n",
       " 'Blenniidae': (2, 7),\n",
       " 'Cyclopsettidae': (1, 1),\n",
       " 'Bovichtidae': (1, 1),\n",
       " 'Botiidae': (5, 6),\n",
       " 'Gobiidae': (44, 55),\n",
       " 'Serranidae': (11, 14),\n",
       " 'Odontobutidae': (1, 3),\n",
       " 'Esocidae': (2, 2),\n",
       " 'Apogonidae': (18, 20),\n",
       " 'Nemacheilidae': (13, 13),\n",
       " 'Anguillidae': (4, 4),\n",
       " 'Syngnathidae': (5, 7),\n",
       " 'Acheilognathidae': (6, 8),\n",
       " 'Retropinnidae': (1, 1),\n",
       " 'Pseudochromidae': (0, 1),\n",
       " 'Lotidae': (1, 1),\n",
       " 'Aphaniidae': (4, 4),\n",
       " 'Leuciscidae': (40, 42),\n",
       " 'Cottidae': (18, 18),\n",
       " 'Macrouridae': (8, 8),\n",
       " 'Scombridae': (5, 6),\n",
       " 'Badidae': (0, 1),\n",
       " 'Gobionidae': (17, 19),\n",
       " 'Liparidae': (3, 3),\n",
       " 'Etmopteridae': (5, 5),\n",
       " 'Rivulidae': (8, 9),\n",
       " 'Acipenseridae': (6, 6),\n",
       " 'Zoarcidae': (3, 3),\n",
       " 'Aulorhynchidae': (0, 1),\n",
       " 'Gastromyzontidae': (7, 7),\n",
       " 'Synanceiidae': (0, 1),\n",
       " 'Xenocyprididae': (9, 10),\n",
       " 'Labridae': (17, 23),\n",
       " 'Zenionidae': (1, 1),\n",
       " 'Grammicolepididae': (2, 2),\n",
       " 'Pomacentridae': (15, 16),\n",
       " 'Tetraodontidae': (10, 11),\n",
       " 'Cichlidae': (12, 16),\n",
       " 'Gonorynchidae': (0, 1),\n",
       " 'Pomacanthidae': (2, 4),\n",
       " 'Mugilidae': (9, 12),\n",
       " 'Ereuniidae': (1, 1),\n",
       " 'Characidae': (6, 6),\n",
       " 'Odacidae': (0, 1),\n",
       " 'Chlorophthalmidae': (0, 2),\n",
       " 'Halosauridae': (1, 1),\n",
       " 'Clupeidae': (9, 10),\n",
       " 'Mullidae': (3, 3),\n",
       " 'Sillaginidae': (1, 1),\n",
       " 'Poeciliidae': (2, 3),\n",
       " 'Chirocentridae': (1, 1),\n",
       " 'Balitoridae': (2, 2),\n",
       " 'Kneriidae': (0, 1),\n",
       " 'Pholidae': (2, 2),\n",
       " 'Evermannellidae': (1, 1),\n",
       " 'Myctophidae': (8, 8),\n",
       " 'Cobitidae': (6, 7),\n",
       " 'Exocoetidae': (1, 1),\n",
       " 'Osphronemidae': (14, 20),\n",
       " 'Stromateidae': (1, 1),\n",
       " 'Sparidae': (4, 4),\n",
       " 'Gerreidae': (2, 3),\n",
       " 'Kyphosidae': (3, 3),\n",
       " 'Lutjanidae': (7, 8),\n",
       " 'Arhynchobatidae': (1, 1),\n",
       " 'Tetragonuridae': (0, 1),\n",
       " 'Atherinopsidae': (1, 1),\n",
       " 'Callichthyidae': (2, 2),\n",
       " 'Loricariidae': (25, 25),\n",
       " 'Diretmidae': (0, 1),\n",
       " 'Gadidae': (1, 1),\n",
       " 'Triakidae': (1, 1),\n",
       " 'Nandidae': (0, 1),\n",
       " 'Sebastidae': (2, 2),\n",
       " 'Pegasidae': (0, 1),\n",
       " 'Sisoridae': (4, 4),\n",
       " 'Zenarchopteridae': (0, 1),\n",
       " 'Caulophrynidae': (1, 1),\n",
       " 'Dasyatidae': (3, 4),\n",
       " 'Catostomidae': (3, 3),\n",
       " 'Gempylidae': (1, 2),\n",
       " 'Eleotridae': (5, 8),\n",
       " 'Percidae': (9, 10),\n",
       " 'Hexanchidae': (3, 3),\n",
       " 'Regalecidae': (1, 1),\n",
       " 'Nototheniidae': (1, 2),\n",
       " 'Anabantidae': (2, 2),\n",
       " 'Acanthuridae': (3, 3),\n",
       " 'Danionidae': (7, 8),\n",
       " 'Doradidae': (6, 6),\n",
       " 'Tanichthyidae': (1, 1),\n",
       " 'Lateolabracidae': (2, 2),\n",
       " 'Channidae': (2, 3),\n",
       " 'Pimelodidae': (3, 3),\n",
       " 'Synodontidae': (1, 3),\n",
       " 'Glaucostegidae': (1, 1),\n",
       " 'Mormyridae': (3, 3),\n",
       " 'Triglidae': (1, 1),\n",
       " 'Stichaeidae': (2, 2),\n",
       " 'Rhynchobatidae': (1, 1),\n",
       " 'Opistognathidae': (0, 1),\n",
       " 'Centrarchidae': (4, 4),\n",
       " 'Galaxiidae': (1, 1),\n",
       " 'Trichiuridae': (3, 3),\n",
       " 'Salangidae': (1, 1),\n",
       " 'Cheilodactylidae': (1, 1),\n",
       " 'Aulopidae': (1, 1),\n",
       " 'Coryphaenidae': (2, 2),\n",
       " 'Tetrarogidae': (0, 1),\n",
       " 'Megalopidae': (0, 1),\n",
       " 'Nothobranchiidae': (2, 6),\n",
       " 'Muraenidae': (6, 7),\n",
       " 'Oneirodidae': (0, 1),\n",
       " 'Ginglymostomatidae': (0, 1),\n",
       " 'Ephippidae': (2, 2),\n",
       " 'Anomalopidae': (0, 1),\n",
       " 'Haemulidae': (0, 2),\n",
       " 'Centrolophidae': (1, 1),\n",
       " 'Balistidae': (2, 2),\n",
       " 'Ammodytidae': (1, 1),\n",
       " 'Chaetodontidae': (3, 5),\n",
       " 'Lebiasinidae': (1, 1),\n",
       " 'Pleuronectidae': (5, 5),\n",
       " 'Somniosidae': (1, 1),\n",
       " 'Alopiidae': (1, 1),\n",
       " 'Dussumieriidae': (0, 1),\n",
       " 'Caristiidae': (2, 2),\n",
       " 'Austroglanididae': (1, 1),\n",
       " 'Anarhichadidae': (1, 1),\n",
       " 'Embiotocidae': (1, 1),\n",
       " 'Myliobatidae': (3, 3),\n",
       " 'Pangasiidae': (1, 1),\n",
       " 'Alepocephalidae': (4, 4),\n",
       " 'Phycidae': (1, 1),\n",
       " 'Citharidae': (0, 1),\n",
       " 'Distichodontidae': (1, 3),\n",
       " 'Trichodontidae': (0, 1),\n",
       " 'Bagridae': (6, 6),\n",
       " 'Synaphobranchidae': (2, 2),\n",
       " 'Sciaenidae': (4, 5),\n",
       " 'Aplocheilidae': (0, 1),\n",
       " 'Moridae': (2, 2),\n",
       " 'Mastacembelidae': (2, 2),\n",
       " 'Elassomatidae': (5, 5),\n",
       " 'Emmelichthyidae': (0, 1),\n",
       " 'Cynoglossidae': (1, 3),\n",
       " 'Hexagrammidae': (1, 1),\n",
       " 'Engraulidae': (3, 6),\n",
       " 'Holocentridae': (5, 5),\n",
       " 'Chaunacidae': (1, 1),\n",
       " 'Scorpaenidae': (1, 2),\n",
       " 'Sternoptychidae': (1, 1),\n",
       " 'Parabembridae': (1, 1),\n",
       " 'Triacanthodidae': (1, 1),\n",
       " 'Paralepididae': (1, 1),\n",
       " 'Diplomystidae': (1, 1),\n",
       " 'Plotosidae': (2, 2),\n",
       " 'Cyclopteridae': (1, 1),\n",
       " 'Priacanthidae': (1, 2),\n",
       " 'Polyprionidae': (0, 1),\n",
       " 'Microstomatidae': (1, 1),\n",
       " 'Dactylopteridae': (0, 2),\n",
       " 'Lethrinidae': (1, 1),\n",
       " 'Monacanthidae': (4, 7),\n",
       " 'Percichthyidae': (2, 2),\n",
       " 'Ophidiidae': (0, 2),\n",
       " 'Argentinidae': (1, 1),\n",
       " 'Soleidae': (1, 2),\n",
       " 'Oreosomatidae': (1, 1),\n",
       " 'Congridae': (3, 3),\n",
       " 'Paralichthyidae': (2, 2),\n",
       " 'Gigantactinidae': (0, 1),\n",
       " 'Siganidae': (1, 1),\n",
       " 'Bryconidae': (1, 1),\n",
       " 'Curimatidae': (1, 1),\n",
       " 'Fistulariidae': (1, 1),\n",
       " 'Trachichthyidae': (0, 1),\n",
       " 'Ostraciidae': (0, 1),\n",
       " 'Gymnuridae': (1, 1),\n",
       " 'Stomiidae': (2, 4),\n",
       " 'Hapalogenyidae': (0, 2),\n",
       " 'Lophotidae': (0, 1),\n",
       " 'Heptapteridae': (0, 1),\n",
       " 'Centrophoridae': (1, 1),\n",
       " 'Notacanthidae': (1, 1),\n",
       " 'Elopidae': (1, 1),\n",
       " 'Gaidropsaridae': (0, 1),\n",
       " 'Ceratiidae': (0, 1),\n",
       " 'Toxotidae': (2, 2),\n",
       " 'Channichthyidae': (0, 1),\n",
       " 'Hemiramphidae': (1, 2),\n",
       " 'Goodeidae': (1, 1),\n",
       " 'Scyliorhinidae': (2, 2),\n",
       " 'Sinipercidae': (2, 2),\n",
       " 'Serrasalmidae': (1, 1),\n",
       " 'Schilbidae': (0, 1),\n",
       " 'Cyprinodontidae': (2, 2),\n",
       " 'Cyematidae': (0, 1),\n",
       " 'Polymixiidae': (0, 1),\n",
       " 'Serrivomeridae': (1, 1),\n",
       " 'Creediidae': (0, 1),\n",
       " 'Anoplopomatidae': (1, 1),\n",
       " 'Agonidae': (1, 1),\n",
       " 'Ailiidae': (0, 1),\n",
       " 'Pristigasteridae': (0, 1),\n",
       " 'Odontaspididae': (0, 1),\n",
       " 'Scophthalmidae': (1, 1),\n",
       " 'Leiognathidae': (0, 1),\n",
       " 'Howellidae': (2, 2),\n",
       " 'Polyodontidae': (1, 1),\n",
       " 'Plesiopidae': (1, 1),\n",
       " 'Cepolidae': (0, 2),\n",
       " 'Pentacerotidae': (2, 2),\n",
       " 'Trachipteridae': (0, 1),\n",
       " 'Gobiesocidae': (0, 2),\n",
       " 'Heterodontidae': (1, 1),\n",
       " 'Cirrhitidae': (1, 1),\n",
       " 'Malacanthidae': (1, 1),\n",
       " 'Neoscopelidae': (1, 1),\n",
       " 'Datnioididae': (1, 1),\n",
       " 'Ophichthidae': (3, 3),\n",
       " 'Cetopsidae': (0, 1),\n",
       " 'Malakichthyidae': (1, 1),\n",
       " 'Sternopygidae': (1, 1),\n",
       " 'Narcinidae': (0, 1),\n",
       " 'Lobotidae': (1, 1),\n",
       " 'Percopsidae': (1, 1),\n",
       " 'Moronidae': (1, 1),\n",
       " 'Artedidraconidae': (1, 1),\n",
       " 'Alepisauridae': (0, 1),\n",
       " 'Symphysanodontidae': (1, 1),\n",
       " 'Dalatiidae': (1, 1),\n",
       " 'Claroteidae': (1, 1),\n",
       " 'Amblycipitidae': (1, 1),\n",
       " 'Himantolophidae': (1, 1),\n",
       " 'Bregmacerotidae': (1, 1),\n",
       " 'Gasteropelecidae': (0, 1),\n",
       " 'Achiridae': (0, 1),\n",
       " 'Osteoglossidae': (0, 1),\n",
       " 'Epigonidae': (0, 1),\n",
       " 'Schindleriidae': (0, 1),\n",
       " 'Derichthyidae': (1, 1),\n",
       " 'Centriscidae': (1, 1),\n",
       " 'Cetomimidae': (2, 2),\n",
       " 'Ipnopidae': (1, 1),\n",
       " 'Ogcocephalidae': (0, 1),\n",
       " 'Rhombosoleidae': (1, 1),\n",
       " 'Ictaluridae': (3, 3),\n",
       " 'Psilorhynchidae': (0, 1),\n",
       " 'Trachinidae': (0, 1),\n",
       " 'Tripterygiidae': (0, 1),\n",
       " 'Pristidae': (1, 1),\n",
       " 'Hemiscylliidae': (1, 1),\n",
       " 'Torpedinidae': (0, 1),\n",
       " 'Alestidae': (1, 1),\n",
       " 'Aracanidae': (1, 1),\n",
       " 'Hiodontidae': (1, 1),\n",
       " 'Squalidae': (1, 1),\n",
       " 'Pinguipedidae': (2, 2),\n",
       " 'Echeneidae': (1, 1),\n",
       " 'Pseudopimelodidae': (1, 1),\n",
       " 'Terapontidae': (1, 1),\n",
       " 'Valenciidae': (1, 1),\n",
       " 'Acropomatidae': (1, 1),\n",
       " 'Dactyloscopidae': (0, 1),\n",
       " 'Siluridae': (1, 1),\n",
       " 'Platytroctidae': (0, 1),\n",
       " 'Melanocetidae': (1, 1),\n",
       " 'Bothidae': (3, 3),\n",
       " 'Albulidae': (1, 1),\n",
       " 'Osmeridae': (1, 1),\n",
       " 'Umbridae': (1, 1),\n",
       " 'Rhinobatidae': (1, 1),\n",
       " 'Bathysauridae': (0, 1),\n",
       " 'Citharinidae': (1, 1),\n",
       " 'Chimaeridae': (1, 1),\n",
       " 'Triacanthidae': (0, 1),\n",
       " 'Trichonotidae': (0, 1),\n",
       " 'Oplegnathidae': (1, 1),\n",
       " 'Muraenolepididae': (1, 1),\n",
       " 'Caproidae': (1, 1),\n",
       " 'Bythitidae': (0, 2),\n",
       " 'Muraenesocidae': (0, 1),\n",
       " 'Lepisosteidae': (1, 1),\n",
       " 'Platycephalidae': (0, 2),\n",
       " 'Labrisomidae': (1, 2),\n",
       " 'Samaridae': (0, 1),\n",
       " 'Peristediidae': (1, 1),\n",
       " 'Bramidae': (1, 1),\n",
       " 'Zeidae': (1, 1),\n",
       " 'Polycentridae': (0, 1),\n",
       " 'Erythrinidae': (0, 1),\n",
       " 'Scopelarchidae': (1, 1),\n",
       " 'Parazenidae': (0, 1),\n",
       " 'Nomeidae': (1, 1),\n",
       " 'Ariommatidae': (2, 2),\n",
       " 'Apteronotidae': (1, 1),\n",
       " 'Batrachoididae': (0, 1),\n",
       " 'Rhinochimaeridae': (1, 1),\n",
       " 'Percophidae': (0, 1),\n",
       " 'Berycidae': (1, 1),\n",
       " 'Callionymidae': (0, 1),\n",
       " 'Merlucciidae': (0, 1),\n",
       " 'Giganturidae': (1, 1),\n",
       " 'Linophrynidae': (1, 1),\n",
       " 'Anablepidae': (1, 1),\n",
       " 'Moringuidae': (1, 1),\n",
       " 'Ariidae': (1, 1),\n",
       " 'Clariidae': (1, 1),\n",
       " 'Centropomidae': (1, 1),\n",
       " 'Uranoscopidae': (0, 1)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(np.array(predictions_train) == np.array(labels_train)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro accuracy sur famille augmentÃ© ( 302 familles ) : 1.6323357947920716\n",
      "Micro accuracy sur famille augmentÃ© ( 302 familles ) : 0.46156933574152115\n"
     ]
    }
   ],
   "source": [
    "count_val=test_df['family'].value_counts()\n",
    "family=count_val.keys()\n",
    "\n",
    "macro_no_augment=(0,0)\n",
    "macro_augment=(0,0)\n",
    "\n",
    "micro_acc_no_augment=[]\n",
    "micro_acc_augment=[]\n",
    "\n",
    "for f in family:\n",
    "\n",
    "    succes,total=dict_score[f]\n",
    "\n",
    "    # if count_val[f] > 97:\n",
    "\n",
    "        \n",
    "\n",
    "    #     macro_no_augment=macro_no_augment[0]+succes,macro_no_augment[1]+total\n",
    "    #     micro_acc_no_augment.append(succes/total)\n",
    "\n",
    "    # else :\n",
    "    #     macro_augment=macro_augment[0]+succes,macro_augment[1]+total\n",
    "    #     micro_acc_augment.append(succes/total)\n",
    "\n",
    "    \n",
    "    macro_augment=macro_augment[0]+succes,macro_augment[1]+total\n",
    "    micro_acc_augment.append(succes/total)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# print(f'Macro accuracy sur famille non augmentÃ© ( {len(micro_acc_no_augment)} familles ) : {100*macro_no_augment[0]/macro_no_augment[1]}')\n",
    "# print(f'Micro accuracy sur famille non augmentÃ© ( {len(micro_acc_no_augment)} familles ) : {100*np.mean(micro_acc_no_augment)}')\n",
    "\n",
    "\n",
    "print(f'Macro accuracy sur famille augmentÃ© ( {len(micro_acc_augment)} familles ) : {100*macro_augment[0]/macro_augment[1]}')\n",
    "print(f'Micro accuracy sur famille augmentÃ© ( {len(micro_acc_augment)} familles ) : {100*np.mean(micro_acc_augment)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_score_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m micro_acc_augment\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m family:\n\u001b[1;32m---> 12\u001b[0m     succes,total\u001b[38;5;241m=\u001b[39m\u001b[43mdict_score_train\u001b[49m[f]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count_val[f] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m97\u001b[39m:\n\u001b[0;32m     18\u001b[0m         macro_no_augment\u001b[38;5;241m=\u001b[39mmacro_no_augment[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39msucces,macro_no_augment[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mtotal\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_score_train' is not defined"
     ]
    }
   ],
   "source": [
    "count_val=val_df['family'].value_counts()\n",
    "family=count_val.keys()\n",
    "\n",
    "macro_no_augment=(0,0)\n",
    "macro_augment=(0,0)\n",
    "\n",
    "micro_acc_no_augment=[]\n",
    "micro_acc_augment=[]\n",
    "\n",
    "for f in family:\n",
    "\n",
    "    succes,total=dict_score_train[f]\n",
    "\n",
    "    if count_val[f] > 97:\n",
    "\n",
    "        \n",
    "\n",
    "        macro_no_augment=macro_no_augment[0]+succes,macro_no_augment[1]+total\n",
    "        micro_acc_no_augment.append(succes/total)\n",
    "\n",
    "    else :\n",
    "        macro_augment=macro_augment[0]+succes,macro_augment[1]+total\n",
    "        micro_acc_augment.append(succes/total)\n",
    "\n",
    "print(f'Macro accuracy sur famille non augmentÃ© ( {len(micro_acc_no_augment)} familles ) : {100*macro_no_augment[0]/macro_no_augment[1]}')\n",
    "print(f'Micro accuracy sur famille non augmentÃ© ( {len(micro_acc_no_augment)} familles ) : {100*np.mean(micro_acc_no_augment)}')\n",
    "\n",
    "\n",
    "print(f'Macro accuracy sur famille augmentÃ© ( {len(micro_acc_augment)} familles ) : {100*macro_augment[0]/macro_augment[1]}')\n",
    "print(f'Micro accuracy sur famille augmentÃ© ( {len(micro_acc_augment)} familles ) : {100*np.mean(micro_acc_augment)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  : 95.5397442326981\n",
      "accurcy moyenne sur famille ( 1283 familles ) : 95.45409594360271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count_val=val_df['family'].value_counts()\n",
    "family=count_val.keys()\n",
    "\n",
    "macro=(0,0)\n",
    "\n",
    "micro=[]\n",
    "\n",
    "for f in family:\n",
    "\n",
    "    succes,total=dict_score[f]\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    macro=macro[0]+succes,macro[1]+total\n",
    "    micro.append(succes/total)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print(f'accuracy  : {100*macro[0]/macro[1]}')\n",
    "print(f'accurcy moyenne sur famille ( {len(micro)} familles ) : {100*np.mean(micro)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/114567 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\envs\\dna\\lib\\site-packages\\transformers\\pipelines\\base.py:1080: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114567/114567 [24:08<00:00, 79.10it/s]\n"
     ]
    }
   ],
   "source": [
    "labels_train,predictions_train, dict_score_train = calculate_predictions(r\"C:\\Users\\Auguste Verdier\\Desktop\\ADNe\\BerTeleo\\data\\Data12S\\FinetuningData\\RawData\\full_dataset_teleo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  : 2.2320875855604094\n",
      "accurcy moyenne sur famille ( 1283 familles ) : 4.0808801283304215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count_val=val_df['family'].value_counts()\n",
    "family=count_val.keys()\n",
    "\n",
    "macro=(0,0)\n",
    "\n",
    "micro=[]\n",
    "\n",
    "for f in family:\n",
    "\n",
    "    succes,total=dict_score_train[f]\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    macro=macro[0]+succes,macro[1]+total\n",
    "    micro.append(succes/total)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print(f'accuracy  : {100*macro[0]/macro[1]}')\n",
    "print(f'accurcy moyenne sur famille ( {len(micro)} familles ) : {100*np.mean(micro)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
